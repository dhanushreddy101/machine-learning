{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bdc96c5-7caa-4cce-bad2-4ae78aaadb8c",
      "metadata": {
        "id": "4bdc96c5-7caa-4cce-bad2-4ae78aaadb8c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = r\"C:\\Users\\DELL E6440\\Desktop\\Payel\\Dec\\12 Dec\\NS2024012017 (Py)\\Tesco.csv\"\n",
        "try:\n",
        "    tesco_data = pd.read_csv(file_path)\n",
        "    tesco_data.head()\n",
        "except Exception as e:\n",
        "    str(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e753e86e-f96b-41d0-b613-19445ad7a0cb",
      "metadata": {
        "id": "e753e86e-f96b-41d0-b613-19445ad7a0cb",
        "outputId": "c0cb0195-7457-4a86-e94f-56569ebca928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7043 entries, 0 to 7042\n",
            "Data columns (total 21 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   customerID        7043 non-null   object \n",
            " 1   gender            7043 non-null   object \n",
            " 2   SeniorCitizen     7043 non-null   int64  \n",
            " 3   Partner           7043 non-null   object \n",
            " 4   Dependents        7043 non-null   object \n",
            " 5   tenure            7043 non-null   int64  \n",
            " 6   PhoneService      7043 non-null   object \n",
            " 7   MultipleLines     7043 non-null   object \n",
            " 8   InternetService   7043 non-null   object \n",
            " 9   OnlineSecurity    7043 non-null   object \n",
            " 10  OnlineBackup      7043 non-null   object \n",
            " 11  DeviceProtection  7043 non-null   object \n",
            " 12  TechSupport       7043 non-null   object \n",
            " 13  StreamingTV       7043 non-null   object \n",
            " 14  StreamingMovies   7043 non-null   object \n",
            " 15  Contract          7043 non-null   object \n",
            " 16  PaperlessBilling  7043 non-null   object \n",
            " 17  PaymentMethod     7043 non-null   object \n",
            " 18  MonthlyCharges    7043 non-null   float64\n",
            " 19  TotalCharges      7043 non-null   object \n",
            " 20  LeftMembership    7043 non-null   object \n",
            "dtypes: float64(1), int64(2), object(18)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ],
      "source": [
        "# Display dataset information to understand its structure\n",
        "tesco_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbb686cc-a0a1-42d5-9343-401395effffc",
      "metadata": {
        "id": "cbb686cc-a0a1-42d5-9343-401395effffc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e97f600-4988-405c-947b-f2c6ec0933f7",
      "metadata": {
        "id": "1e97f600-4988-405c-947b-f2c6ec0933f7"
      },
      "outputs": [],
      "source": [
        "# Preprocessing the dataset\n",
        "# Dropping irrelevant columns\n",
        "tesco_data = tesco_data.drop(columns=[\"customerID\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84244e50-43d2-4408-85be-02ffbfa45a65",
      "metadata": {
        "id": "84244e50-43d2-4408-85be-02ffbfa45a65"
      },
      "outputs": [],
      "source": [
        "# Encoding categorical variables\n",
        "label_encoders = {}\n",
        "for column in tesco_data.select_dtypes(include=[\"object\"]).columns:\n",
        "    if column != \"LeftMembership\":\n",
        "        le = LabelEncoder()\n",
        "        tesco_data[column] = le.fit_transform(tesco_data[column].astype(str))\n",
        "        label_encoders[column] = le"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "027a4415-8d11-4383-a727-8c5bd077efd8",
      "metadata": {
        "id": "027a4415-8d11-4383-a727-8c5bd077efd8"
      },
      "outputs": [],
      "source": [
        "# Encode target variable\n",
        "target_encoder = LabelEncoder()\n",
        "tesco_data[\"LeftMembership\"] = target_encoder.fit_transform(tesco_data[\"LeftMembership\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a0e6594-f1b4-4f1f-8c4a-c82d7e0b2d3d",
      "metadata": {
        "id": "8a0e6594-f1b4-4f1f-8c4a-c82d7e0b2d3d"
      },
      "outputs": [],
      "source": [
        "# Splitting data into features and target\n",
        "X = tesco_data.drop(columns=[\"LeftMembership\"])\n",
        "y = tesco_data[\"LeftMembership\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "583770d9-9129-42ac-a51b-c83762833299",
      "metadata": {
        "id": "583770d9-9129-42ac-a51b-c83762833299"
      },
      "outputs": [],
      "source": [
        "# Splitting into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f4e559f-6f6c-41a7-9d12-81b48de636ad",
      "metadata": {
        "id": "7f4e559f-6f6c-41a7-9d12-81b48de636ad"
      },
      "outputs": [],
      "source": [
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f23adc8-7b15-48ef-9ede-4c0934ee58d1",
      "metadata": {
        "id": "7f23adc8-7b15-48ef-9ede-4c0934ee58d1"
      },
      "outputs": [],
      "source": [
        "# One-hot encoding target variable\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cf89132-f469-486d-80b5-f603955f0280",
      "metadata": {
        "id": "5cf89132-f469-486d-80b5-f603955f0280",
        "outputId": "9a44183d-39b6-47be-b06a-de036784d2f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DELL E6440\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Building the MLP model\n",
        "model = Sequential([\n",
        "    Dense(64, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dropout(0.3),\n",
        "    Dense(2, activation=\"softmax\")  # Output layer with softmax for binary classification\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a501873-1de0-4af2-82e4-3ad5d2a2746e",
      "metadata": {
        "id": "9a501873-1de0-4af2-82e4-3ad5d2a2746e"
      },
      "outputs": [],
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "986656d9-749b-4918-b4a5-87daf455877d",
      "metadata": {
        "id": "986656d9-749b-4918-b4a5-87daf455877d",
        "outputId": "48f094ad-4637-4ef8-a53e-85e9b7e1583d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6980 - loss: 0.5706 - val_accuracy: 0.7782 - val_loss: 0.4516\n",
            "Epoch 2/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7941 - loss: 0.4434 - val_accuracy: 0.7835 - val_loss: 0.4473\n",
            "Epoch 3/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7848 - loss: 0.4444 - val_accuracy: 0.7782 - val_loss: 0.4469\n",
            "Epoch 4/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7785 - loss: 0.4464 - val_accuracy: 0.7826 - val_loss: 0.4451\n",
            "Epoch 5/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7860 - loss: 0.4312 - val_accuracy: 0.7773 - val_loss: 0.4463\n",
            "Epoch 6/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8018 - loss: 0.4215 - val_accuracy: 0.7728 - val_loss: 0.4478\n",
            "Epoch 7/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8006 - loss: 0.4254 - val_accuracy: 0.7782 - val_loss: 0.4440\n",
            "Epoch 8/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8051 - loss: 0.4216 - val_accuracy: 0.7915 - val_loss: 0.4442\n",
            "Epoch 9/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8050 - loss: 0.4141 - val_accuracy: 0.7844 - val_loss: 0.4443\n",
            "Epoch 10/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8001 - loss: 0.4133 - val_accuracy: 0.7844 - val_loss: 0.4429\n",
            "Epoch 11/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8079 - loss: 0.4073 - val_accuracy: 0.7826 - val_loss: 0.4431\n",
            "Epoch 12/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8010 - loss: 0.4202 - val_accuracy: 0.7791 - val_loss: 0.4462\n",
            "Epoch 13/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8102 - loss: 0.4001 - val_accuracy: 0.7817 - val_loss: 0.4444\n",
            "Epoch 14/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8139 - loss: 0.4125 - val_accuracy: 0.7799 - val_loss: 0.4445\n",
            "Epoch 15/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8205 - loss: 0.4028 - val_accuracy: 0.7799 - val_loss: 0.4460\n",
            "Epoch 16/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8032 - loss: 0.4154 - val_accuracy: 0.7782 - val_loss: 0.4438\n",
            "Epoch 17/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8089 - loss: 0.3986 - val_accuracy: 0.7782 - val_loss: 0.4447\n",
            "Epoch 18/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8097 - loss: 0.4138 - val_accuracy: 0.7853 - val_loss: 0.4439\n",
            "Epoch 19/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8123 - loss: 0.4044 - val_accuracy: 0.7826 - val_loss: 0.4452\n",
            "Epoch 20/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8255 - loss: 0.3829 - val_accuracy: 0.7879 - val_loss: 0.4436\n"
          ]
        }
      ],
      "source": [
        "# Training the model\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "385d80b6-052a-46ac-bc52-806f0c004561",
      "metadata": {
        "id": "385d80b6-052a-46ac-bc52-806f0c004561"
      },
      "outputs": [],
      "source": [
        "# Evaluating the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "test_accuracy, test_loss"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}